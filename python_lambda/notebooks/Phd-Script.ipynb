{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!git pull\n",
    "import os;os.environ['LAMBDA_PARQUET_TICK_DB']=rf'X:\\lambda_data'\n",
    "session_name='Phd-Script'\n",
    "import time\n",
    "import datetime\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "from notebooks.lambda_imports import *\n",
    "dill.load_session(session_name)\n",
    "\n",
    "TRAIN_DQN=False\n",
    "DEBUG=False\n",
    "PLOT_CANDLES=True\n",
    "HURST_TEST=True\n",
    "PARAMETER_TUNING_BENCHMARK_INITIAL=False\n",
    "PARAMETER_TUNING_BENCHMARK=True\n",
    "\n",
    "elapsed = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_number=666\n",
    "np.random.seed(seed_number)\n",
    "import random\n",
    "random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from avellaneda stoikov\n",
    "best_avellaneda_param_dict={'risk_aversion': 0.01,\n",
    " 'position_multiplier': 100.0,\n",
    " 'window_tick': 20.936773236619324,\n",
    " 'minutes_change_k': 10.0,\n",
    " 'quantity': 0.0001,\n",
    " 'k_default': 1.68688291488258,\n",
    " 'spread_multiplier': 2.0,\n",
    " 'first_hour': 7.0,\n",
    " 'last_hour': 19.0}\n",
    "\n",
    "#from feature importance\n",
    "most_significant_state_columns=[\n",
    " 'ask_price_0',\n",
    " 'ask_price_2',\n",
    " 'ask_price_4',\n",
    " 'ask_price_8',\n",
    " 'ask_qty_0',\n",
    " 'ask_qty_1',\n",
    " 'ask_qty_2',\n",
    " 'ask_qty_7',\n",
    " 'bid_price_0',\n",
    " 'bid_price_2',\n",
    " 'bid_price_4',\n",
    " 'bid_price_6',\n",
    " 'bid_price_8',\n",
    " 'bid_qty_0',\n",
    " 'bid_qty_1',\n",
    " 'bid_qty_7',\n",
    " 'close_0',\n",
    " 'low_0',\n",
    " 'ma',\n",
    " 'microprice_0',\n",
    " 'microprice_7',\n",
    " 'midprice_0',\n",
    " 'spread_0',\n",
    " 'spread_2',\n",
    " 'spread_4',\n",
    " 'spread_8'\n",
    "]\n",
    "# most_significant_state_columns=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_pk='btcusdt_binance'\n",
    "\n",
    "# start_date_pt=datetime.datetime(year=2020, day=8, month=12,hour=9)\n",
    "# end_date_pt=datetime.datetime(year=2020, day=8, month=12,hour=13)\n",
    "\n",
    "# start_date_train=end_date_pt+datetime.timedelta(hours=1)#not here\n",
    "# end_date_train=start_date_train+datetime.timedelta(hours=2)#not here\n",
    "\n",
    "# start_date_train=datetime.datetime(year=2020, day=8, month=12,hour=9)\n",
    "# end_date_train=datetime.datetime(year=2020, day=8, month=12,hour=21)\n",
    "start_date_train=datetime.datetime(year=2020, day=8, month=12,hour=9)\n",
    "end_date_train=datetime.datetime(year=2020, day=8, month=12,hour=16)\n",
    "#complete day of training\n",
    "\n",
    "start_date_test=datetime.datetime(year=2020, day=9, month=12,hour=9)\n",
    "end_date_test=datetime.datetime(year=2020, day=9, month=12,hour=11)\n",
    "\n",
    "\n",
    "start_date_test_1=end_date_test+datetime.timedelta(minutes=10)#not here\n",
    "end_date_test_1=start_date_test_1+datetime.timedelta(hours=2)#not here\n",
    "\n",
    "start_date_test_2=end_date_test_1+datetime.timedelta(minutes=10)#not here\n",
    "end_date_test_2=start_date_test_2+datetime.timedelta(hours=2)#not here\n",
    "\n",
    "start_date_test_3=end_date_test_2+datetime.timedelta(minutes=10)#not here\n",
    "end_date_test_3=start_date_test_3+datetime.timedelta(hours=2)#not here\n",
    "\n",
    "# start_date_test_4=end_date_test_3+datetime.timedelta(minutes=10)#not here\n",
    "# end_date_test_4=start_date_test_4+datetime.timedelta(hours=2)#not here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = TickDB()\n",
    "depth_data = tick.get_depth(instrument_pk=instrument_pk,start_date=start_date_train,end_date=end_date_test_3)\n",
    "trade_data = tick.get_trades(instrument_pk=instrument_pk,start_date=start_date_train,end_date=end_date_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HURST_TEST:\n",
    "    from hurst import compute_Hc, random_walk\n",
    "    ###hurst exponents\n",
    "    # H = 0.5 — Brownian motion,\n",
    "    # 0.5 < H < 1.0 — persistent behavior,\n",
    "    # 0 < H < 0.5 — anti-persistent behavior.\n",
    "    ts=candle_data['price']['close']\n",
    "    hurst_table = {}\n",
    "\n",
    "    H_train, c, data = compute_Hc(ts.loc[start_date_train:end_date_train], kind='price', simplified=True)\n",
    "    H_test1, c, data = compute_Hc(ts.loc[start_date_test:end_date_test], kind='price', simplified=True)\n",
    "    H_test2, c, data = compute_Hc(ts.loc[start_date_test_1:end_date_test_1], kind='price', simplified=True)\n",
    "    H_test3, c, data = compute_Hc(ts.loc[start_date_test_2:end_date_test_2], kind='price', simplified=True)\n",
    "    H_test4, c, data = compute_Hc(ts.loc[start_date_test_3:end_date_test_3], kind='price', simplified=True)\n",
    "#     H_test5, c, data = compute_Hc(ts.loc[start_date_test_4:end_date_test_4], kind='price', simplified=True)\n",
    "\n",
    "    hurst_table['train']= [H_train,'trending']\n",
    "    hurst_table['test1']=[H_test1,'trending']\n",
    "    hurst_table['test2']=[H_test2,'trending']\n",
    "    hurst_table['test3']=[H_test3,'trending']\n",
    "    hurst_table['test4']=[H_test4,'mean_reversion']\n",
    "#     hurst_table['test5']=[H_test5,'mean_reversion']\n",
    "    hurst_df = pd.DataFrame.from_dict(hurst_table).T\n",
    "    hurst_df.columns=['Hurst exponent','classification']\n",
    "    hurst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HURST_TEST:\n",
    "    print(f\"train hurst:{H_train}\")\n",
    "    print(f\"test1 hurst:{H_test1}\")\n",
    "    print(f\"test2 hurst:{H_test2}\")\n",
    "    print(f\"test3 hurst:{H_test3}\")\n",
    "    print(f\"test4 hurst:{H_test4}\")\n",
    "#     print(f\"test5 hurst:{H_test5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "if PLOT_CANDLES:\n",
    "    candle_data = trade_data.resample('1Min').ohlc()\n",
    "    candle_data_plot = candle_data.loc[start_date_train:end_date_test].append(candle_data.loc[start_date_test_1:end_date_test_4])\n",
    "    candle_data_plot['price_open']=candle_data_plot['price']['open']\n",
    "    candle_data_plot['price_high']=candle_data_plot['price']['high']\n",
    "    candle_data_plot['price_low']=candle_data_plot['price']['low']\n",
    "    candle_data_plot['price_close']=candle_data_plot['price']['close']\n",
    "    \n",
    "\n",
    "\n",
    "    candlestick = go.Candlestick(\n",
    "        x=candle_data_plot.index,\n",
    "        open=candle_data_plot['price_open'],\n",
    "        high=candle_data_plot['price_high'],\n",
    "        low=candle_data_plot['price_low'],\n",
    "        close=candle_data_plot['price_close']\n",
    "    )\n",
    "    fig = go.Figure(data=[candlestick])\n",
    "\n",
    "    # plotly line figure\n",
    "    # fig.update_layout(\n",
    "    #     title='Pipeline',\n",
    "    #     yaxis_title=instrument_pk,\n",
    "    #     shapes = [dict(\n",
    "    #         x0=end_date_train, x1=end_date_train, y0=0, y1=1, xref='x', yref='paper',\n",
    "    #         line_width=2)],\n",
    "    #     annotations=[dict(\n",
    "    #         x=end_date_train, y=0.05, xref='x', yref='paper',\n",
    "    #         showarrow=False, xanchor='left', text='end train')]\n",
    "    # )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Pipeline',\n",
    "        yaxis_title=instrument_pk,\n",
    "        shapes = [\n",
    "            dict(\n",
    "            x0=start_date_train, x1=start_date_train, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "\n",
    "            dict(\n",
    "            x0=end_date_train, x1=end_date_train, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=start_date_test, x1=start_date_test, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=end_date_test, x1=end_date_test, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "\n",
    "                  dict(\n",
    "            x0=start_date_test_1, x1=start_date_test_1, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=end_date_test_1, x1=end_date_test_1, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "\n",
    "                  dict(\n",
    "            x0=start_date_test_2, x1=start_date_test_2, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=end_date_test_2, x1=end_date_test_2, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=start_date_test_3, x1=start_date_test_3, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "                  dict(\n",
    "            x0=end_date_test_3, x1=end_date_test_3, y0=0, y1=1, xref='x', yref='paper',\n",
    "            line_width=1),\n",
    "#                   dict(\n",
    "#             x0=start_date_test_4, x1=start_date_test_4, y0=0, y1=1, xref='x', yref='paper',\n",
    "#             line_width=1),\n",
    "#                   dict(\n",
    "#             x0=end_date_test_4, x1=end_date_test_4, y0=0, y1=1, xref='x', yref='paper',\n",
    "#             line_width=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                 ],\n",
    "        annotations=[\n",
    "            dict(\n",
    "            x=start_date_train, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='start train',height = 16),\n",
    "\n",
    "            dict(\n",
    "            x=end_date_train, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='end train'),\n",
    "\n",
    "            dict(\n",
    "            x=start_date_test, y=0.05, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='start test1'),\n",
    "\n",
    "            dict(\n",
    "            x=end_date_test, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='end test1'),\n",
    "\n",
    "\n",
    "            dict(\n",
    "            x=start_date_test_1, y=0.05, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='start test2'),\n",
    "\n",
    "            dict(\n",
    "            x=end_date_test_1, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='end test2')   ,\n",
    "\n",
    "            dict(\n",
    "            x=start_date_test_2, y=0.05, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='start test3'),\n",
    "\n",
    "            dict(\n",
    "            x=end_date_test_2, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='end test3')   ,\n",
    "\n",
    "                    dict(\n",
    "            x=start_date_test_3, y=0.05, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='start test4'),\n",
    "\n",
    "            dict(\n",
    "            x=end_date_test_3, y=0.1, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='left', text='end test4')   ,\n",
    "\n",
    "#                     dict(\n",
    "#             x=start_date_test_4, y=0.05, xref='x', yref='paper',\n",
    "#             showarrow=False, xanchor='left', text='start test5'),\n",
    "\n",
    "#             dict(\n",
    "#             x=end_date_test_4, y=0.1, xref='x', yref='paper',\n",
    "#             showarrow=False, xanchor='left', text='end test5') \n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning_benchmark(benchmark_algorithm,start_date,end_date,best_parameter_tuning_dict=None):\n",
    "    parameters_min = {\"risk_aversion\":0.01,'window_tick':5,'k_default':0. ,'spread_multiplier':1.}\n",
    "    parameters_max = {\"risk_aversion\":0.9, 'window_tick':25,'k_default':2. ,'spread_multiplier':2.}\n",
    "    \n",
    "    \n",
    "    ga_configuration = GAConfiguration\n",
    "    if DEBUG:\n",
    "        ga_configuration.population = 15\n",
    "        ga_configuration_generations=3\n",
    "        ga_configuration_simultaneous=15\n",
    "    else:\n",
    "        ga_configuration.population = 45\n",
    "        ga_configuration_generations=10\n",
    "        ga_configuration_simultaneous=25\n",
    "        \n",
    "    if best_parameter_tuning_dict is not None:\n",
    "        ga_configuration.population = 15\n",
    "        ga_configuration_generations=3\n",
    "        ga_configuration_simultaneous=5\n",
    "        pct_moving=0.2\n",
    "        min_pct=1-pct_moving\n",
    "        max_pct=1+pct_moving\n",
    "        parameters_min = {\"risk_aversion\":best_parameter_tuning_dict[\"risk_aversion\"]*min_pct,'window_tick':int(best_parameter_tuning_dict[\"window_tick\"]*min_pct),'k_default':best_parameter_tuning_dict[\"k_default\"]*min_pct ,'spread_multiplier':best_parameter_tuning_dict[\"spread_multiplier\"]*min_pct}\n",
    "        parameters_max = {\"risk_aversion\":best_parameter_tuning_dict[\"risk_aversion\"]*max_pct,'window_tick':int(best_parameter_tuning_dict[\"window_tick\"]*max_pct),'k_default':best_parameter_tuning_dict[\"k_default\"]*max_pct ,'spread_multiplier':best_parameter_tuning_dict[\"spread_multiplier\"]*max_pct}\n",
    "        \n",
    "        \n",
    "    ga_configuration.decay=1/float(ga_configuration_generations)\n",
    "    \n",
    "    best_param_dict, summary_df =benchmark_algorithm.parameter_tuning(\n",
    "        instrument_pk=instrument_pk,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        parameters_min=parameters_min,\n",
    "        parameters_max=parameters_max,\n",
    "        generations=ga_configuration_generations,\n",
    "        ga_configuration=ga_configuration,\n",
    "        max_simultaneous=ga_configuration_simultaneous\n",
    "    )\n",
    "    benchmark_algorithm.set_parameters(best_param_dict)\n",
    "    return benchmark_algorithm,best_param_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVELLANEDA STOIKOV - BENCHMARK\n",
    "parameters_default_as = {\n",
    "    # Avellaneda default\n",
    "    \"risk_aversion\": (0.9),\n",
    "    \"position_multiplier\": (100),\n",
    "    \"window_tick\": (10),\n",
    "    \"minutes_change_k\": (10),\n",
    "    \"quantity\": (0.0001),\n",
    "    \"k_default\": (0.00769),\n",
    "    \"spread_multiplier\": (5.0),\n",
    "    \"first_hour\": (7),\n",
    "    \"last_hour\": (19),\n",
    "}\n",
    "\n",
    "algorithm_info_as='avellaneda_stoikov'\n",
    "benchmark = AvellanedaStoikov(algorithm_info=algorithm_info_as,parameters=parameters_default_as)\n",
    "benchmark.set_parameters(best_avellaneda_param_dict)\n",
    "\n",
    "if PARAMETER_TUNING_BENCHMARK_INITIAL:\n",
    "    print('launching parameter tuning ')\n",
    "    benchmark,best_avellaneda_param_dict=parameter_tuning_benchmark(benchmark,start_date=start_date_train,end_date=end_date_train)\n",
    "    print(f'finished parameter tuning with score {best_avellaneda_param_dict}')\n",
    "else:\n",
    "    print(f'Parameter tuning loaded with params {best_avellaneda_param_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQN Avellaneda stoikov\n",
    "parameters_default_dqn = {\n",
    "    # Q\n",
    "    \"skewPricePctAction\": [0.,0.05,-0.05,-0.1,0.1],\n",
    "    \"riskAversionAction\": [0.01,.1,0.2,0.9],\n",
    "    \"windowsTickAction\": [8],\n",
    "    \n",
    "    \"minPrivateState\": (-1),\n",
    "    \"maxPrivateState\": (-1),\n",
    "    \"numberDecimalsPrivateState\":(3),\n",
    "    \"horizonTicksPrivateState\": (5),\n",
    "    \n",
    "    \"minMarketState\": (-1),\n",
    "    \"maxMarketState\": (-1),\n",
    "    \"numberDecimalsMarketState\": (7),\n",
    "    \"horizonTicksMarketState\": (10),\n",
    "    \n",
    "    \"horizonMinMsTick\": (0),\n",
    "    \n",
    "    \"minCandleState\": (-1),\n",
    "    \"maxCandleState\": (-1),\n",
    "    \"numberDecimalsCandleState\": (3),\n",
    "    \"horizonCandlesState\": (2),\n",
    "    \n",
    "    \"scoreEnum\": ScoreEnum.asymmetric_dampened_pnl,\n",
    "    \"timeHorizonSeconds\": (5),\n",
    "    \"epsilon\": (0.2),#explore prob\n",
    "    \"discountFactor\": 0.5,#momentum nesterov nn\n",
    "    \"learningRate\": 0.01,#on nn\n",
    "    # Avellaneda default\n",
    "    \"risk_aversion\": (0.9),\n",
    "    \"position_multiplier\": (100),\n",
    "    \"window_tick\": (10),\n",
    "    \"minutes_change_k\": (10),\n",
    "    \"quantity\": (0.0001),\n",
    "    \"k_default\": (0.00769),\n",
    "    \"spread_multiplier\": (5.0),\n",
    "    \"first_hour\": (7),\n",
    "    \"last_hour\": (19),\n",
    "    #DQN\n",
    "    \"maxBatchSize\": 100000,\n",
    "    \"trainingPredictIterationPeriod\": -1,  # train only at the end,offline\n",
    "    \"trainingTargetIterationPeriod\": -1,  # train at the end,offline\n",
    "    \"epoch\": 2000,\n",
    "    \"stateColumnsFilter\": most_significant_state_columns,\n",
    "    \"l1\":0.,\n",
    "    \"l2\":0.,\n",
    "    \n",
    "}\n",
    "\n",
    "algorithm_info_dqn='avellaneda_stoikov_dqn'\n",
    "\n",
    "avellaneda_dqn = AvellanedaDQN(algorithm_info=algorithm_info_dqn,parameters=parameters_default_dqn)\n",
    "avellaneda_dqn.set_parameters(best_avellaneda_param_dict)#same optimization as benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "if TRAIN_DQN:    \n",
    "    if DEBUG:\n",
    "        algos_per_iteration = 5\n",
    "        iterations_train=3\n",
    "        train_simultaneous=5\n",
    "    else:\n",
    "        algos_per_iteration = 5\n",
    "        iterations_train=50\n",
    "        train_simultaneous=5\n",
    "\n",
    "\n",
    "    output_train_list=avellaneda_dqn.train(\n",
    "            instrument_pk=instrument_pk,\n",
    "            start_date=start_date_train,\n",
    "            end_date=end_date_train,\n",
    "            iterations=iterations_train,\n",
    "            algos_per_iteration=algos_per_iteration,\n",
    "            simultaneous_algos=train_simultaneous,\n",
    "        )\n",
    "    dill.dump_session(session_name)\n",
    "else:\n",
    "    print('using previous trained model')\n",
    "elapsed=time.time()-start\n",
    "print('train of %d iterations finished in %.2f minutes'%(iterations_train,elapsed/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DQN:\n",
    "    memory_replay_out=avellaneda_dqn.get_memory_replay_df(\"E:\\javif\\Coding\\Python\\market_making_fw\\python_lambda\\output\\memoryReplay_AvellanedaDQN_avellaneda_stoikov_dqn_0.csv\")\n",
    "    memory_replay_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DQN:\n",
    "    memory_replay_out.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_DQN:\n",
    "    #first iteration results\n",
    "    name_output=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_1'\n",
    "    backtest_result_train_init=output_train_list[0][name_output]\n",
    "    plot_1=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_train_init,plot_open=True)\n",
    "    \n",
    "    filename='dqn_train_initial.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)    \n",
    "    plt.show()\n",
    "    \n",
    "    plot_1a=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_train_init)    \n",
    "    filename='dqn_train_params_initial.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    legends=[]\n",
    "    for algorithm_iter in range(algos_per_iteration):\n",
    "        name_output_iter=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter\n",
    "        backtest_result_train_init_iter=output_train_list[0][name_output_iter]\n",
    "        backtest_result_train_init_iter['historicalTotalPnl'].plot()\n",
    "        legends.append(avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter)\n",
    "    plt.title('all initial algos')\n",
    "    plt.legend(legends)    \n",
    "    filename='dqn_train_all_initial.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_DQN:    \n",
    "    iteration_quarter=round(len(output_train_list)/4)\n",
    "    backtest_result_train_quarter=output_train_list[iteration_quarter][name_output]\n",
    "    plot_2=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_train_quarter,plot_open=True)\n",
    "    \n",
    "    filename='dqn_train_quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_2a=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_train_quarter)    \n",
    "    filename='dqn_train_params_quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    legends=[]\n",
    "    for algorithm_iter in range(algos_per_iteration):\n",
    "        name_output_iter=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter\n",
    "        backtest_result_train_mid_iter=output_train_list[iteration_quarter][name_output_iter]\n",
    "        backtest_result_train_mid_iter['historicalTotalPnl'].plot()\n",
    "        legends.append(avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter)\n",
    "    plt.title('all quarter algos')\n",
    "    plt.legend(legends)    \n",
    "    filename='dqn_train_all_quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_DQN:    \n",
    "    iteration_middle=round(len(output_train_list)/2)\n",
    "    backtest_result_train_mid=output_train_list[iteration_middle][name_output]\n",
    "    plot_2=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_train_mid,plot_open=True)\n",
    "    \n",
    "    filename='dqn_train_middle.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_2a=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_train_mid)    \n",
    "    filename='dqn_train_params_middle.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    legends=[]\n",
    "    for algorithm_iter in range(algos_per_iteration):\n",
    "        name_output_iter=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter\n",
    "        backtest_result_train_mid_iter=output_train_list[iteration_middle][name_output_iter]\n",
    "        backtest_result_train_mid_iter['historicalTotalPnl'].plot()\n",
    "        legends.append(avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter)\n",
    "    plt.title('all middle algos')\n",
    "    plt.legend(legends)    \n",
    "    filename='dqn_train_all_middle.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_DQN:    \n",
    "    iteration_75=round(len(output_train_list)*3/4)\n",
    "    backtest_result_train_iteration_75=output_train_list[iteration_75][name_output]\n",
    "    plot_2=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_train_iteration_75,plot_open=True)\n",
    "    \n",
    "    filename='dqn_train_3quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_2a=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_train_iteration_75)    \n",
    "    filename='dqn_train_params_3quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    legends=[]\n",
    "    for algorithm_iter in range(algos_per_iteration):\n",
    "        name_output_iter=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter\n",
    "        backtest_result_train_mid_iter=output_train_list[iteration_75][name_output_iter]\n",
    "        backtest_result_train_mid_iter['historicalTotalPnl'].plot()\n",
    "        legends.append(avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter)\n",
    "    plt.title('all 3xquarter algos')\n",
    "    plt.legend(legends)    \n",
    "    filename='dqn_train_all_3quarter.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_DQN:\n",
    "    #last iteration results\n",
    "    backtest_result_train_final=output_train_list[-1][name_output]\n",
    "    plot_3=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_train_final,plot_open=True)\n",
    "    filename='dqn_train_final.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_3a=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_train_final)    \n",
    "    filename='dqn_train_params_final.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    legends=[]\n",
    "    for algorithm_iter in range(algos_per_iteration):\n",
    "        name_output_iter=avellaneda_dqn.NAME+'_'+avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter\n",
    "        backtest_result_train_final_iter=output_train_list[-1][name_output_iter]\n",
    "        backtest_result_train_final_iter['historicalTotalPnl'].plot()\n",
    "        legends.append(avellaneda_dqn.algorithm_info+'_%d'%algorithm_iter)\n",
    "    plt.title('all final algos')\n",
    "    plt.legend(legends)    \n",
    "    filename='dqn_train_all_final.png'\n",
    "    plt.savefig(filename)\n",
    "    files.append(filename)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iteration_quarter=%d   iteration_middle=%d   iteration_75=%d'%(iteration_quarter,iteration_middle,iteration_75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_test = {}\n",
    "# parameter_test['epsilon']=0.0\n",
    "# avellaneda_dqn.set_parameters(parameter_test)\n",
    "# avellaneda_dqn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_prob=0.\n",
    "trainingPredictIterationPeriod=50\n",
    "trainingTargetIterationPeriod=200\n",
    "counter_plt_results=0\n",
    "wining_counter=0\n",
    "final_results_columns=['instrument','benchmark_open_pnl','benchmark_close_pnl','benchmark_sharpe','benchmark_trades','rl_open_pnl','rl_close_pnl','rl_sharpe','rl_trades']\n",
    "final_results=pd.DataFrame(columns=final_results_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_test(start_date_test,end_date_test,is_parameter_tuning_benchmark:bool=False,start_date_train=None,end_date_train=None,best_parameter_tuning_dict:dict=None):\n",
    "    best_avellaneda_param_dict=None\n",
    "    if is_parameter_tuning_benchmark:        \n",
    "        best_benchmark_algorithm,best_avellaneda_param_dict=parameter_tuning_benchmark(benchmark,start_date=start_date_train,end_date=end_date_train,best_parameter_tuning_dict=best_parameter_tuning_dict)\n",
    "        #set new bet parameter tuning\n",
    "        benchmark.set_parameters(best_avellaneda_param_dict)\n",
    "        avellaneda_dqn.set_parameters(best_avellaneda_param_dict)#to be fair optimization is going to optimize avellaneda\n",
    "        \n",
    "    \n",
    "    benchmark_test = benchmark.test(\n",
    "        instrument_pk=instrument_pk,\n",
    "        start_date=start_date_test,\n",
    "        end_date=end_date_test,\n",
    "    )\n",
    "    \n",
    "    dqn_test = avellaneda_dqn.test(\n",
    "        instrument_pk=instrument_pk,\n",
    "        start_date=start_date_test,\n",
    "        end_date=end_date_test,\n",
    "        explore_prob=explore_prob,\n",
    "        trainingPredictIterationPeriod=trainingPredictIterationPeriod,\n",
    "        trainingTargetIterationPeriod=trainingTargetIterationPeriod,\n",
    "    )\n",
    "    return benchmark_test,dqn_test,best_avellaneda_param_dict\n",
    "\n",
    "\n",
    "\n",
    "def plot_results_algorithms(benchmark_test,dqn_test,save_file=True):\n",
    "    global counter_plt_results\n",
    "    global wining_counter\n",
    "    \n",
    "    name_output=benchmark.algorithm_info\n",
    "    plot_open=True\n",
    "    #AS\n",
    "    backtest_result_test=benchmark_test[name_output]\n",
    "    plot_bnch=benchmark.plot_trade_results(raw_trade_pnl_df=backtest_result_test,plot_open=plot_open)\n",
    "    filename='benchmark_test_%d.png'%counter_plt_results\n",
    "    if save_file:\n",
    "        plt.savefig(filename)\n",
    "        files.append(filename)\n",
    "    plt.show()    \n",
    "    \n",
    "    #DQN\n",
    "    name_output=avellaneda_dqn.algorithm_info\n",
    "    backtest_result_test=dqn_test[name_output]    \n",
    "    plot_dqn=avellaneda_dqn.plot_trade_results(raw_trade_pnl_df=backtest_result_test,plot_open=plot_open)\n",
    "    filename='dqn_test_%d.png'%counter_plt_results\n",
    "    if save_file:\n",
    "        plt.savefig(filename)\n",
    "        files.append(filename)\n",
    "\n",
    "    plot_dqnA=avellaneda_dqn.plot_params(raw_trade_pnl_df=backtest_result_test)    \n",
    "    filename='dqn_test_%d_params.png'%counter_plt_results\n",
    "    if save_file:\n",
    "        plt.savefig(filename)\n",
    "        files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    #compare\n",
    "#     column_to_compare='historicalRealizedPnl'\n",
    "    column_to_compare='historicalTotalPnl'#\n",
    "    import copy\n",
    "    benchmark_result = copy.copy(benchmark_test[benchmark.algorithm_info])\n",
    "    benchmark_result.set_index('date',inplace=True)\n",
    "    \n",
    "    dqn_result = copy.copy(dqn_test[avellaneda_dqn.algorithm_info])\n",
    "    dqn_result.set_index('date',inplace=True)\n",
    "    \n",
    "    \n",
    "    total_pnl=pd.concat([benchmark_result[column_to_compare],dqn_result[column_to_compare]],axis=1)\n",
    "    total_pnl.columns=['%s_benchmark'%column_to_compare,'%s_dqn'%column_to_compare]\n",
    "    total_pnl.sort_index(inplace=True)\n",
    "    \n",
    "    total_pnl.fillna(method='ffill',axis=0,inplace=True)\n",
    "    total_pnl.dropna(inplace=True)\n",
    "    \n",
    "    total_pnl.plot(figsize=(17,7))\n",
    "\n",
    "    sharpe_as=total_pnl['%s_benchmark'%column_to_compare].diff().mean()/total_pnl['%s_benchmark'%column_to_compare].diff().std()\n",
    "    sharpe_dqn=total_pnl['%s_dqn'%column_to_compare].diff().mean()/total_pnl['%s_dqn'%column_to_compare].diff().std()\n",
    "    legend=['benchmark sharpe=%.5f  pnl=%.3f'%(sharpe_as,total_pnl['%s_benchmark'%column_to_compare].iloc[-1]),'dqn sharpe=%.5f  pnl=%.3f'%(sharpe_dqn,total_pnl['%s_dqn'%column_to_compare].iloc[-1])]\n",
    "    if sharpe_dqn>sharpe_as:\n",
    "        wining_counter+=1\n",
    "        \n",
    "    as_open_pnl=benchmark_test[benchmark.algorithm_info]['historicalTotalPnl'].iloc[-1]\n",
    "    as_close_pnl=benchmark_test[benchmark.algorithm_info]['historicalRealizedPnl'].iloc[-1]\n",
    "    as_sharpe=sharpe_as\n",
    "    as_trades=len(benchmark_test[benchmark.algorithm_info])\n",
    "    \n",
    "    rl_open_pnl=dqn_test[avellaneda_dqn.algorithm_info]['historicalTotalPnl'].iloc[-1]\n",
    "    rl_close_pnl=dqn_test[avellaneda_dqn.algorithm_info]['historicalRealizedPnl'].iloc[-1]\n",
    "    rl_sharpe=sharpe_dqn\n",
    "    rl_trades=len(dqn_test[avellaneda_dqn.algorithm_info])\n",
    "    \n",
    "    \n",
    "    row=[instrument_pk,as_open_pnl,as_close_pnl,as_sharpe,as_trades,\n",
    "     rl_open_pnl,rl_close_pnl,rl_sharpe,rl_trades]\n",
    "    final_results.loc[len(final_results)]=row\n",
    "        \n",
    "    plt.title('%s test_%d'%(column_to_compare,counter_plt_results))\n",
    "    plt.legend(legend)\n",
    "    plt.xlabel('trade number')\n",
    "    filename='compare_total_pnl_%d.png'%counter_plt_results\n",
    "    if save_file:\n",
    "        plt.savefig(filename)\n",
    "        files.append(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    file_output='dqn_vs_as_output_%d.csv'%counter_plt_results\n",
    "    files.append(file_output)\n",
    "    if save_file:\n",
    "        total_pnl.to_csv(file_output)\n",
    "    counter_plt_results+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "days_test = [\n",
    "    datetime.datetime(2020,12,9),\n",
    "    datetime.datetime(2020,12,10),\n",
    "    datetime.datetime(2020,12,11),\n",
    "    datetime.datetime(2020,12,12),    \n",
    "    datetime.datetime(2020,12,13),\n",
    "    \n",
    "    datetime.datetime(2020,12,14),\n",
    "    datetime.datetime(2020,12,15),\n",
    "    datetime.datetime(2020,12,16),    \n",
    "    datetime.datetime(2020,12,17),\n",
    "    datetime.datetime(2020,12,18),\n",
    "    \n",
    "    datetime.datetime(2020,12,19),\n",
    "    datetime.datetime(2020,12,20),\n",
    "    datetime.datetime(2020,12,21),\n",
    "    datetime.datetime(2020,12,22),\n",
    "    datetime.datetime(2020,12,23),\n",
    "    \n",
    "    datetime.datetime(2020,12,24),\n",
    "    datetime.datetime(2020,12,25),\n",
    "    datetime.datetime(2020,12,26),\n",
    "    datetime.datetime(2020,12,27),\n",
    "    datetime.datetime(2020,12,28),\n",
    "    \n",
    "    datetime.datetime(2020,12,29),\n",
    "    datetime.datetime(2020,12,30),\n",
    "    datetime.datetime(2021,1,1),\n",
    "    datetime.datetime(2021,1,2),\n",
    "    datetime.datetime(2021,1,3),\n",
    "    \n",
    "    datetime.datetime(2021,1,4),\n",
    "    datetime.datetime(2021,1,5),\n",
    "    datetime.datetime(2021,1,6),\n",
    "    datetime.datetime(2021,1,7),\n",
    "    datetime.datetime(2021,1,8),\n",
    "    \n",
    "]\n",
    "days_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parameter_tuning_every_n_days=5\n",
    "\n",
    "final_results_columns=['instrument','benchmark_open_pnl','benchmark_close_pnl','benchmark_sharpe','benchmark_trades','rl_open_pnl','rl_close_pnl','rl_sharpe','rl_trades']\n",
    "final_results=pd.DataFrame(columns=final_results_columns)\n",
    "start_date_train = None\n",
    "end_date_train = None\n",
    "day_counter=0\n",
    "for day in tqdm.tqdm(days_test):\n",
    "    start_date = day\n",
    "    end_date=day\n",
    "    if start_date_train is None or day_counter%parameter_tuning_every_n_days!=0:\n",
    "        benchmark_test_temp,dqn_test_temp,best_parameter_dict=launch_test(start_date,end_date) \n",
    "        best_parameter_dict=best_avellaneda_param_dict#initially \n",
    "    else:\n",
    "        print(f'Parameter tuning benchmark on day {day_counter} with data from {start_date_train} to {end_date_train}')\n",
    "        benchmark_test_temp,dqn_test_temp,best_parameter_dict=launch_test(start_date,end_date,is_parameter_tuning_benchmark=PARAMETER_TUNING_BENCHMARK,start_date_train=start_date_train,end_date_train=end_date_train,best_parameter_tuning_dict=best_parameter_dict)\n",
    "        \n",
    "        \n",
    "    plot_results_algorithms(benchmark_test_temp,dqn_test_temp,save_file=False)\n",
    "    start_date_train=start_date\n",
    "    end_date_train=end_date\n",
    "    day_counter+=1\n",
    "    \n",
    "final_results['date']=days_test\n",
    "final_results.set_index('date',inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['is_better_sharpe']=final_results['rl_sharpe']>final_results['benchmark_sharpe']\n",
    "final_results['is_better_open_pnl']=final_results['rl_open_pnl']>final_results['benchmark_open_pnl']\n",
    "final_results['is_better_close_pnl']=final_results['rl_close_pnl']>final_results['benchmark_close_pnl']\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[['is_better_sharpe','is_better_open_pnl','is_better_close_pnl']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[['is_better_sharpe','is_better_open_pnl','is_better_close_pnl']].describe().to_csv('statistical_significance_test_results.csv')\n",
    "files.append('statistical_significance_test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('statistical_significance_test.csv')\n",
    "files.append('statistical_significance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('win %d times of total %d '%(wining_counter,counter_plt_results))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=list(set(files))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files=['statistical_significance_test_results.csv','statistical_significance_test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wining_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str='LOSE'\n",
    "if (wining_counter>counter_plt_results/2):\n",
    "    result_str='WIN'\n",
    "result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook_session(session_name)\n",
    "send_email(recipient='javifalces@gmail.com',subject='[%s]PhdScript finished %s -> win ratio %d/%d '%(datetime.datetime.today(),result_str,wining_counter,counter_plt_results),html=final_results_modified.to_html(),body='',file_append=files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
